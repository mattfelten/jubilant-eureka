[
  {
    "partition_id": 0,
    "offset": 0,
    "timestamp": 1622548800000,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 1,
    "offset": 0,
    "timestamp": 1622548800100,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-7800\"}"
  },
  {
    "partition_id": 2,
    "offset": 0,
    "timestamp": 1622548800200,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Started inference\", \"request_id\": \"req-7088\"}"
  },
  {
    "partition_id": 0,
    "offset": 1,
    "timestamp": 1622548800300,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Completed inference\", \"request_id\": \"req-2950\", \"latency_ms\": 150}"
  },
  {
    "partition_id": 1,
    "offset": 1,
    "timestamp": 1622548800400,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"High latency detected\", \"request_id\": \"req-4672\", \"latency_ms\": 78}"
  },
  {
    "partition_id": 2,
    "offset": 1,
    "timestamp": 1622548800500,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Inference failed\", \"request_id\": \"req-3936\", \"error\": \"timeout\"}"
  },
  {
    "partition_id": 0,
    "offset": 2,
    "timestamp": 1622548800600,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache hit for prompt\", \"prompt_hash\": \"0xdccbfd\"}"
  },
  {
    "partition_id": 1,
    "offset": 2,
    "timestamp": 1622548800700,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache miss for prompt\", \"prompt_hash\": \"0xa47049\"}"
  },
  {
    "partition_id": 2,
    "offset": 2,
    "timestamp": 1622548800800,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"POST\", \"endpoint\": \"/api/v1/inference\"}"
  },
  {
    "partition_id": 0,
    "offset": 3,
    "timestamp": 1622548800900,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"GET\", \"endpoint\": \"/api/v1/models\"}"
  },
  {
    "partition_id": 1,
    "offset": 3,
    "timestamp": 1622548801000,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Failed to load model segment\", \"segment\": 3, \"error\": \"missing weights\"}"
  },
  {
    "partition_id": 2,
    "offset": 3,
    "timestamp": 1622548801100,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Scaling replicas\", \"model\": \"openai-gpt-3\", \"replicas\": 5}"
  },
  {
    "partition_id": 0,
    "offset": 4,
    "timestamp": 1622548801200,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"Replica unhealthy\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 1,
    "offset": 4,
    "timestamp": 1622548801300,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Request queue length\", \"queue_length\": 41}"
  },
  {
    "partition_id": 2,
    "offset": 4,
    "timestamp": 1622548801400,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Warm-up inference sent\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 0,
    "offset": 5,
    "timestamp": 1622548801500,
    "log": "{\"level\": \"DEBUG\", \"service\": \"health\", \"message\": \"Health check passed\", \"model\": \"openai-gpt-3-4\"}"
  },
  {
    "partition_id": 1,
    "offset": 5,
    "timestamp": 1622548801600,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 2,
    "offset": 5,
    "timestamp": 1622548801700,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-6681\"}"
  },
  {
    "partition_id": 0,
    "offset": 6,
    "timestamp": 1622548801800,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Started inference\", \"request_id\": \"req-8748\"}"
  },
  {
    "partition_id": 1,
    "offset": 6,
    "timestamp": 1622548801900,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Completed inference\", \"request_id\": \"req-3426\", \"latency_ms\": 454}"
  },
  {
    "partition_id": 2,
    "offset": 6,
    "timestamp": 1622548802000,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"High latency detected\", \"request_id\": \"req-6209\", \"latency_ms\": 227}"
  },
  {
    "partition_id": 0,
    "offset": 7,
    "timestamp": 1622548802100,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Inference failed\", \"request_id\": \"req-2007\", \"error\": \"timeout\"}"
  },
  {
    "partition_id": 1,
    "offset": 7,
    "timestamp": 1622548802200,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache hit for prompt\", \"prompt_hash\": \"0xa1851d\"}"
  },
  {
    "partition_id": 2,
    "offset": 7,
    "timestamp": 1622548802300,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache miss for prompt\", \"prompt_hash\": \"0x19c1a8\"}"
  },
  {
    "partition_id": 0,
    "offset": 8,
    "timestamp": 1622548802400,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"POST\", \"endpoint\": \"/api/v1/inference\"}"
  },
  {
    "partition_id": 1,
    "offset": 8,
    "timestamp": 1622548802500,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"GET\", \"endpoint\": \"/api/v1/models\"}"
  },
  {
    "partition_id": 2,
    "offset": 8,
    "timestamp": 1622548802600,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Failed to load model segment\", \"segment\": 3, \"error\": \"missing weights\"}"
  },
  {
    "partition_id": 0,
    "offset": 9,
    "timestamp": 1622548802700,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Scaling replicas\", \"model\": \"openai-gpt-3\", \"replicas\": 5}"
  },
  {
    "partition_id": 1,
    "offset": 9,
    "timestamp": 1622548802800,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"Replica unhealthy\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 2,
    "offset": 9,
    "timestamp": 1622548802900,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Request queue length\", \"queue_length\": 34}"
  },
  {
    "partition_id": 0,
    "offset": 10,
    "timestamp": 1622548803000,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Warm-up inference sent\", \"replica_id\": \"openai-gpt-3-5\"}"
  },
  {
    "partition_id": 1,
    "offset": 10,
    "timestamp": 1622548803100,
    "log": "{\"level\": \"DEBUG\", \"service\": \"health\", \"message\": \"Health check passed\", \"model\": \"openai-gpt-3-4\"}"
  },
  {
    "partition_id": 2,
    "offset": 10,
    "timestamp": 1622548803200,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 0,
    "offset": 11,
    "timestamp": 1622548803300,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-8432\"}"
  },
  {
    "partition_id": 1,
    "offset": 11,
    "timestamp": 1622548803400,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Started inference\", \"request_id\": \"req-6224\"}"
  },
  {
    "partition_id": 2,
    "offset": 11,
    "timestamp": 1622548803500,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Completed inference\", \"request_id\": \"req-6565\", \"latency_ms\": 106}"
  },
  {
    "partition_id": 0,
    "offset": 12,
    "timestamp": 1622548803600,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"High latency detected\", \"request_id\": \"req-6000\", \"latency_ms\": 161}"
  },
  {
    "partition_id": 1,
    "offset": 12,
    "timestamp": 1622548803700,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Inference failed\", \"request_id\": \"req-8669\", \"error\": \"timeout\"}"
  },
  {
    "partition_id": 2,
    "offset": 12,
    "timestamp": 1622548803800,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache hit for prompt\", \"prompt_hash\": \"0x889621\"}"
  },
  {
    "partition_id": 0,
    "offset": 13,
    "timestamp": 1622548803900,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache miss for prompt\", \"prompt_hash\": \"0x95587e\"}"
  },
  {
    "partition_id": 1,
    "offset": 13,
    "timestamp": 1622548804000,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"POST\", \"endpoint\": \"/api/v1/inference\"}"
  },
  {
    "partition_id": 2,
    "offset": 13,
    "timestamp": 1622548804100,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"GET\", \"endpoint\": \"/api/v1/models\"}"
  },
  {
    "partition_id": 0,
    "offset": 14,
    "timestamp": 1622548804200,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Failed to load model segment\", \"segment\": 3, \"error\": \"missing weights\"}"
  },
  {
    "partition_id": 1,
    "offset": 14,
    "timestamp": 1622548804300,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Scaling replicas\", \"model\": \"openai-gpt-3\", \"replicas\": 5}"
  },
  {
    "partition_id": 2,
    "offset": 14,
    "timestamp": 1622548804400,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"Replica unhealthy\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 0,
    "offset": 15,
    "timestamp": 1622548804500,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Request queue length\", \"queue_length\": 11}"
  },
  {
    "partition_id": 1,
    "offset": 15,
    "timestamp": 1622548804600,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Warm-up inference sent\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 2,
    "offset": 15,
    "timestamp": 1622548804700,
    "log": "{\"level\": \"DEBUG\", \"service\": \"health\", \"message\": \"Health check passed\", \"model\": \"openai-gpt-3-4\"}"
  },
  {
    "partition_id": 0,
    "offset": 16,
    "timestamp": 1622548804800,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 1,
    "offset": 16,
    "timestamp": 1622548804900,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-7046\"}"
  },
  {
    "partition_id": 2,
    "offset": 16,
    "timestamp": 1622548805000,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Started inference\", \"request_id\": \"req-9658\"}"
  },
  {
    "partition_id": 0,
    "offset": 17,
    "timestamp": 1622548805100,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Completed inference\", \"request_id\": \"req-8291\", \"latency_ms\": 255}"
  },
  {
    "partition_id": 1,
    "offset": 17,
    "timestamp": 1622548805200,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"High latency detected\", \"request_id\": \"req-9130\", \"latency_ms\": 85}"
  },
  {
    "partition_id": 2,
    "offset": 17,
    "timestamp": 1622548805300,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Inference failed\", \"request_id\": \"req-6813\", \"error\": \"timeout\"}"
  },
  {
    "partition_id": 0,
    "offset": 18,
    "timestamp": 1622548805400,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache hit for prompt\", \"prompt_hash\": \"0x4a24f4\"}"
  },
  {
    "partition_id": 1,
    "offset": 18,
    "timestamp": 1622548805500,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache miss for prompt\", \"prompt_hash\": \"0x336588\"}"
  },
  {
    "partition_id": 2,
    "offset": 18,
    "timestamp": 1622548805600,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"POST\", \"endpoint\": \"/api/v1/inference\"}"
  },
  {
    "partition_id": 0,
    "offset": 19,
    "timestamp": 1622548805700,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"GET\", \"endpoint\": \"/api/v1/models\"}"
  },
  {
    "partition_id": 1,
    "offset": 19,
    "timestamp": 1622548805800,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Failed to load model segment\", \"segment\": 3, \"error\": \"missing weights\"}"
  },
  {
    "partition_id": 2,
    "offset": 19,
    "timestamp": 1622548805900,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Scaling replicas\", \"model\": \"openai-gpt-3\", \"replicas\": 5}"
  },
  {
    "partition_id": 0,
    "offset": 20,
    "timestamp": 1622548806000,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"Replica unhealthy\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 1,
    "offset": 20,
    "timestamp": 1622548806100,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Request queue length\", \"queue_length\": 18}"
  },
  {
    "partition_id": 2,
    "offset": 20,
    "timestamp": 1622548806200,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Warm-up inference sent\", \"replica_id\": \"openai-gpt-3-1\"}"
  },
  {
    "partition_id": 0,
    "offset": 21,
    "timestamp": 1622548806300,
    "log": "{\"level\": \"DEBUG\", \"service\": \"health\", \"message\": \"Health check passed\", \"model\": \"openai-gpt-3-4\"}"
  },
  {
    "partition_id": 1,
    "offset": 21,
    "timestamp": 1622548806400,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 2,
    "offset": 21,
    "timestamp": 1622548806500,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-7216\"}"
  },
  {
    "partition_id": 0,
    "offset": 22,
    "timestamp": 1622548806600,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Started inference\", \"request_id\": \"req-9778\"}"
  },
  {
    "partition_id": 1,
    "offset": 22,
    "timestamp": 1622548806700,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Completed inference\", \"request_id\": \"req-4932\", \"latency_ms\": 409}"
  },
  {
    "partition_id": 2,
    "offset": 22,
    "timestamp": 1622548806800,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"High latency detected\", \"request_id\": \"req-3004\", \"latency_ms\": 273}"
  },
  {
    "partition_id": 0,
    "offset": 23,
    "timestamp": 1622548806900,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Inference failed\", \"request_id\": \"req-8552\", \"error\": \"timeout\"}"
  },
  {
    "partition_id": 1,
    "offset": 23,
    "timestamp": 1622548807000,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache hit for prompt\", \"prompt_hash\": \"0x8d5fb9\"}"
  },
  {
    "partition_id": 2,
    "offset": 23,
    "timestamp": 1622548807100,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache miss for prompt\", \"prompt_hash\": \"0x27ffdc\"}"
  },
  {
    "partition_id": 0,
    "offset": 24,
    "timestamp": 1622548807200,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"POST\", \"endpoint\": \"/api/v1/inference\"}"
  },
  {
    "partition_id": 1,
    "offset": 24,
    "timestamp": 1622548807300,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"GET\", \"endpoint\": \"/api/v1/models\"}"
  },
  {
    "partition_id": 2,
    "offset": 24,
    "timestamp": 1622548807400,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Failed to load model segment\", \"segment\": 3, \"error\": \"missing weights\"}"
  },
  {
    "partition_id": 0,
    "offset": 25,
    "timestamp": 1622548807500,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Scaling replicas\", \"model\": \"openai-gpt-3\", \"replicas\": 5}"
  },
  {
    "partition_id": 1,
    "offset": 25,
    "timestamp": 1622548807600,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"Replica unhealthy\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 2,
    "offset": 25,
    "timestamp": 1622548807700,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Request queue length\", \"queue_length\": 44}"
  },
  {
    "partition_id": 0,
    "offset": 26,
    "timestamp": 1622548807800,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Warm-up inference sent\", \"replica_id\": \"openai-gpt-3-5\"}"
  },
  {
    "partition_id": 1,
    "offset": 26,
    "timestamp": 1622548807900,
    "log": "{\"level\": \"DEBUG\", \"service\": \"health\", \"message\": \"Health check passed\", \"model\": \"openai-gpt-3-4\"}"
  },
  {
    "partition_id": 2,
    "offset": 26,
    "timestamp": 1622548808000,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 0,
    "offset": 27,
    "timestamp": 1622548808100,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-1951\"}"
  },
  {
    "partition_id": 1,
    "offset": 27,
    "timestamp": 1622548808200,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Started inference\", \"request_id\": \"req-4030\"}"
  },
  {
    "partition_id": 2,
    "offset": 27,
    "timestamp": 1622548808300,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Completed inference\", \"request_id\": \"req-3262\", \"latency_ms\": 387}"
  },
  {
    "partition_id": 0,
    "offset": 28,
    "timestamp": 1622548808400,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"High latency detected\", \"request_id\": \"req-8918\", \"latency_ms\": 162}"
  },
  {
    "partition_id": 1,
    "offset": 28,
    "timestamp": 1622548808500,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Inference failed\", \"request_id\": \"req-1737\", \"error\": \"timeout\"}"
  },
  {
    "partition_id": 2,
    "offset": 28,
    "timestamp": 1622548808600,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache hit for prompt\", \"prompt_hash\": \"0xdfbff1\"}"
  },
  {
    "partition_id": 0,
    "offset": 29,
    "timestamp": 1622548808700,
    "log": "{\"level\": \"DEBUG\", \"service\": \"cache\", \"message\": \"Cache miss for prompt\", \"prompt_hash\": \"0x8b040f\"}"
  },
  {
    "partition_id": 1,
    "offset": 29,
    "timestamp": 1622548808800,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"POST\", \"endpoint\": \"/api/v1/inference\"}"
  },
  {
    "partition_id": 2,
    "offset": 29,
    "timestamp": 1622548808900,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Received request\", \"method\": \"GET\", \"endpoint\": \"/api/v1/models\"}"
  },
  {
    "partition_id": 0,
    "offset": 30,
    "timestamp": 1622548809000,
    "log": "{\"level\": \"ERROR\", \"service\": \"gateway\", \"message\": \"Failed to load model segment\", \"segment\": 3, \"error\": \"missing weights\"}"
  },
  {
    "partition_id": 1,
    "offset": 30,
    "timestamp": 1622548809100,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Scaling replicas\", \"model\": \"openai-gpt-3\", \"replicas\": 5}"
  },
  {
    "partition_id": 2,
    "offset": 30,
    "timestamp": 1622548809200,
    "log": "{\"level\": \"WARN\", \"service\": \"gateway\", \"message\": \"Replica unhealthy\", \"replica_id\": \"openai-gpt-3-2\"}"
  },
  {
    "partition_id": 0,
    "offset": 31,
    "timestamp": 1622548809300,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Request queue length\", \"queue_length\": 1}"
  },
  {
    "partition_id": 1,
    "offset": 31,
    "timestamp": 1622548809400,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Warm-up inference sent\", \"replica_id\": \"openai-gpt-3-1\"}"
  },
  {
    "partition_id": 2,
    "offset": 31,
    "timestamp": 1622548809500,
    "log": "{\"level\": \"DEBUG\", \"service\": \"health\", \"message\": \"Health check passed\", \"model\": \"openai-gpt-3-4\"}"
  },
  {
    "partition_id": 0,
    "offset": 32,
    "timestamp": 1622548809600,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"message\": \"Model loaded\", \"model\": \"openai-gpt-3\"}"
  },
  {
    "partition_id": 1,
    "offset": 32,
    "timestamp": 1622548809700,
    "log": "{\"level\": \"DEBUG\", \"service\": \"gateway\", \"message\": \"Inference request received\", \"request_id\": \"req-6928\"}"
  },
  {
    "partition_id": 2,
    "offset": 32,
    "timestamp": 1622548809800,
    "log": "{\"level\": \"INFO\", \"service\": \"gateway\", \"request_id\": \"req-7890\", \"endpoint\": \"/api/v1/inference\", \"input_prompt\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. ... [truncated for brevity] ..., at vulputate elit velit eu nisi.\n\", \"metadata\": {\"user_id\": 98765, \"session_id\": \"sess-abcde12345\", \"model\": \"openai-gpt-4\"}, \"latency_ms\": 123, \"status\": \"completed\"}"
  },
  {
    "partition_id": 0,
    "offset": 33,
    "timestamp": 1622548809900,
    "log": "{\"level\":\"INFO\",\"service\":\"gateway\",\"request_id\":\"req-9999\",\"endpoint\":\"/api/v1/inference\",\"input_prompt\":\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae velit ex. Mauris venenatis enim nec nisi malesuada, et imperdiet sapien bibendum. Ut non commodo erat. Proin euismod, dolor sit amet faucibus semper, urna metus ultrices purus, at vulputate elit velit eu nisi.\\n\",\"metadata\":{\"user_id\":12345,\"session_id\":\"sess-01234abcd\",\"model\":\"openai-gpt-4-turbo\"},\"latency_ms\":256,\"status\":\"completed\"}"
  }
]